# Hi there, I'm Keshav Kumar Yadav üëã

![Hi GIF](https://media.giphy.com/media/v1.Y2lkPWVjZjA1ZTQ3b2M4bTAzNTlmNWtzdzM3bHMybHc5NGkzdXBna3huanF4M3k2b3YyNyZlcD12MV9naWZzX3NlYXJjaCZjdD1n/VoJqOxw0Zh36Vm8uDD/giphy.gif)

---

### üìä Professional Summary

I am a **Results-driven Data Engineer** with **4 years** of experience specializing in building **scalable data systems, ETL processes, and automation** for global enterprise applications. I am passionate about data reliability, quality, and engineering robust, end-to-end data pipelines.

- **Focus:** Leveraging expertise in **Python, SQL, and modern cloud technologies** to deliver data solutions that drive efficiency and insight.
- **Impact:** Proven track record of **reducing manual effort by 30%** through automation and leading complex data migration projects.
- **Seeking:** Roles where I can apply my skills in database development and modern data engineering tools like **dbt, PySpark, and AWS services** to solve real-world data challenges.

---

### üõ†Ô∏è Core Technology Stack

| Category | Key Technologies & Tools |
| :--- | :--- |
| **Programming** | Python, SQL, PL/SQL, Java |
| **Cloud Platforms** | AWS (S3, Glue, EMR, Redshift, IAM, Lambda) |
| **Big Data** | Apache Spark, PySpark, Apache Kafka |
| **Orchestration** | Apache Airflow, Informatica |
| **Databases** | Oracle, MySQL, NoSQL (MongoDB, Cassandra) |
| **Data Modeling** | dbt (data build tool), Star Schema, Snowflake Schema |
| **DevOps & CI/CD** | Docker, Jenkins, Git, GitHub |

---

### üöÄ Featured Projects & Experience

#### Cloud-Native Data Pipeline (Personal Project)
A fully functional, end-to-end data pipeline built on AWS for processing and transforming large datasets.
- **Architecture:** Used **AWS Glue (PySpark)** for data cleansing and transformations.
- **Modeling:** Employed **dbt** to build efficient data models in **Amazon Redshift**.
- **Deployment:** Containerized components using **Docker** and orchestrated the workflow with **Apache Airflow**.
- **Automation:** Automated build and deployment using a **CI/CD pipeline in Jenkins**.

#### Workday Data Migration
Executed full-scale data extraction, transformation, and validation for Workday onboarding.
- **Role:** SPOC (Single Point of Contact) for the GBS Team.
- **Technical Contribution:** Designed complex **SQL and PL/SQL queries** for data extraction and transformation based on business rules.

---

## üìä GitHub Stats

![Keshav's GitHub stats](https://github-readme-stats.vercel.app/api?username=keshavyadav11k&show_icons=true&theme=tokyonight)

---

‚ú® Always learning, experimenting, and sharing projects that make tech simpler!

---

### üì´ Connect with Me

- **LinkedIn:** [linkedin.com/in/keshav-yadav](https://www.linkedin.com/in/keshav-yadav-483487156/)
- **Email:** [keshav_yadav@email.com](mailto:keshavyadav11K@email.com)
- **Resume:** *(Add a link to your PDF resume here)*
